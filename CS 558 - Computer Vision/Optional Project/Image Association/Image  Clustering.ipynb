{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run the code and check the output folders 'clusterResnet' and 'clusterSIFT' for the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 16:51:00.400789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/varun/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2021-12-18 16:51:00.400815: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SfM_quality_evaluation'...\n",
      "remote: Enumerating objects: 237, done.\u001b[K\n",
      "remote: Total 237 (delta 0), reused 0 (delta 0), pack-reused 237\u001b[K\n",
      "Receiving objects: 100% (237/237), 254.31 MiB | 19.43 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n",
      "Updating files: 100% (214/214), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openMVG/SfM_quality_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_folders = ['fountain-P11', 'Herz-Jesus-P8', 'entry-P10','castle-P19']\n",
    "\n",
    "data_path = 'SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008'\n",
    "\n",
    "if not os.path.exists('dataset'):\n",
    "    os.mkdir('dataset')\n",
    "\n",
    "for folder in desired_folders:\n",
    "    images_path = os.path.join(os.path.join(data_path, folder),'images')\n",
    "    for img in os.listdir(images_path):\n",
    "        if img.endswith('.jpg'):\n",
    "            shutil.copyfile(os.path.join(images_path, img),os.path.join('dataset',\"%s-%s\"%(folder,img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = [cv2.imread(\"dataset/\"+i) for i in os.listdir('dataset')]\n",
    "dataset_images = [cv2.resize(i, (224,224))/255.0 for i in dataset_images]\n",
    "dataset_images = np.array(dataset_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating SIFT data for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_data = []\n",
    "sift = cv2.SIFT_create(3500)\n",
    "\n",
    "img_labels = []\n",
    "\n",
    "for i in os.listdir('dataset'):\n",
    "    grayImg = cv2.cvtColor(cv2.imread('dataset/'+i), cv2.COLOR_BGR2GRAY)\n",
    "    img_labels.append(i)\n",
    "    kp, des = sift.detectAndCompute(grayImg, None)\n",
    "    des = des[:3500]\n",
    "    des = des.flatten()\n",
    "    sift_data.append(des)\n",
    "\n",
    "sift_data = np.array(sift_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Clustering using KMeans and Storing the images in respective Cluster Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 2, 3, 0, 0, 3, 3, 2, 2, 3, 0, 1,\n",
       "       2, 2, 1, 0, 1, 3, 1, 1, 3, 1, 2, 2, 3, 1, 0, 3, 1, 0, 0, 1, 3, 1,\n",
       "       2, 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_sift = KMeans(4, max_iter=1000).fit(sift_data)\n",
    "kmeans_sift.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('clusterSIFT'):\n",
    "    shutil.rmtree('clusterSIFT')\n",
    "os.mkdir('clusterSIFT')\n",
    "\n",
    "for ind, lb in enumerate(kmeans_sift.labels_):\n",
    "\n",
    "    if not os.path.exists('clusterSIFT/'+str(lb)):\n",
    "        os.mkdir('clusterSIFT/%s'%lb)\n",
    "    \n",
    "    shutil.copyfile('dataset/'+img_labels[ind], 'clusterSIFT/%s/%s'%(lb,img_labels[ind]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating ResNEt Data for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 16:52:51.714494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/varun/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2021-12-18 16:52:51.714543: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-18 16:52:51.714579: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VarunUbuntu): /proc/driver/nvidia/version does not exist\n",
      "2021-12-18 16:52:51.714849: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "resnetModel = tf.keras.applications.ResNet50V2(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "resnetOutput = tf.keras.layers.Flatten()(resnetModel.output)\n",
    "resnetModel = tf.keras.models.Model(inputs=resnetModel.input, outputs=resnetOutput)\n",
    "\n",
    "resnet_data = resnetModel.predict(dataset_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Clustering using KMeans and storing data in respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 3, 3, 0, 1, 3, 0, 3, 2, 1, 1, 2, 2, 3, 3, 2, 1, 0,\n",
       "       3, 1, 2, 3, 3, 3, 0, 0, 2, 0, 3, 1, 0, 0, 3, 2, 1, 1, 3, 0, 2, 0,\n",
       "       3, 3, 3, 0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_resnet = KMeans(4, max_iter=1000).fit(resnet_data)\n",
    "kmeans_resnet.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('clusterResnet'):\n",
    "    shutil.rmtree('clusterResnet')\n",
    "os.mkdir('clusterResnet')\n",
    "\n",
    "for ind, lb in enumerate(kmeans_resnet.labels_):\n",
    "\n",
    "    if not os.path.exists('clusterResnet/'+str(lb)):\n",
    "        os.mkdir('clusterResnet/%s'%lb)\n",
    "    \n",
    "    shutil.copyfile('dataset/'+img_labels[ind], 'clusterResnet/%s/%s'%(lb,img_labels[ind]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failed classification for Mean Shift Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_shift = MeanShift(bandwidth=estimate_bandwidth(sift_data, quantile=0.2),max_iter=1000, bin_seeding=True)\n",
    "mean_shift.fit(sift_data)\n",
    "mean_shift.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on the results obtained from above, we can see that KMeans is performing well in clustering compared to the Mean Shift Algorithm, but using the SIFT data to cluster brings some erroneous clusters which are not of same category. But while using a pretrained ResNet model for predicting image descriptors, we were able to succesfully cluster them into respective groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
