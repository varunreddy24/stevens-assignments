{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23933b8f",
   "metadata": {
    "id": "494a8c17"
   },
   "source": [
    "# CS 584 Assignment 3 -- Language Model\n",
    "\n",
    "#### Name: Varun Doddipalli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b66f5",
   "metadata": {
    "id": "9a2591a0"
   },
   "source": [
    "## In this assignment, you are required to follow the steps below:\n",
    "1. Review the lecture slides.\n",
    "2. Implement N-gram language modeling.\n",
    "3. Implement RNN language modeling.\n",
    "\n",
    "*** Please read the code and comments very carefully and install these packages (NumPy, sklearn, and tqdm) before you start ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e161a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a23584bf",
    "outputId": "feb54288-555f-40fa-9358-b4aed6a5a8ac"
   },
   "outputs": [],
   "source": [
    "!pip install numpy scikit-learn tqdm matplotlib\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8753f",
   "metadata": {
    "id": "a4b34034"
   },
   "source": [
    "## 0. Data Process\n",
    "Run the following cells to preprocess training data, validation data, and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e77ae1",
   "metadata": {
    "id": "681c2be5"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991fd1d0",
   "metadata": {
    "id": "6dca548c"
   },
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "with open('./data/train.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        train_texts.append(line)\n",
    "        \n",
    "valid_texts = []\n",
    "with open('./data/valid.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        valid_texts.append(line)\n",
    "        \n",
    "test_texts = []\n",
    "with open('./data/input.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        test_texts.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c5479",
   "metadata": {
    "id": "3121ada5"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c448601",
   "metadata": {
    "id": "806dfdea"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "class Preprocesser(object):\n",
    "    def __init__(self, punctuation=True, url=True, number=True):\n",
    "        self.punctuation = punctuation\n",
    "        self.url = url\n",
    "        self.number = number\n",
    "    \n",
    "    def apply(self, text):\n",
    "        \n",
    "        text = self._lowercase(text)\n",
    "        # text = text.replace('<unk>', '')\n",
    "        \n",
    "        if self.url:\n",
    "            text = self._remove_url(text)\n",
    "            \n",
    "        if self.punctuation:\n",
    "            text = self._remove_punctuation(text)\n",
    "            \n",
    "        if self.number:\n",
    "            text = self._remove_number(text)\n",
    "        \n",
    "        text = '<s> ' + text + ' </s>'\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "        \n",
    "    def _remove_punctuation(self, text):\n",
    "        ''' Please fill this function to remove all the punctuations in the text\n",
    "        '''\n",
    "        ### Start your code\n",
    "        puncs = string.punctuation\n",
    "        puncs = puncs.replace('<', '')\n",
    "        puncs = puncs.replace('>', '')\n",
    "        puncs = puncs.replace('/', '')\n",
    "        text = ''.join(c for c in text if c not in puncs)\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _remove_url(self, text):\n",
    "        ''' Please fill this function to remove all the urls in the text\n",
    "        '''\n",
    "        ### Start your code\n",
    "        \n",
    "        text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text)\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _remove_number(self, text):\n",
    "        ''' Please fill this function to remove all the numbers in the text\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        text = ''.join([i for i in text if not i.isdigit()])\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _lowercase(self, text):\n",
    "        ''' Please fill this function to lower the text\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        text = text.lower()\n",
    "        ### End\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "preprocesser = Preprocesser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf4946",
   "metadata": {
    "id": "407f9491"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6a869f",
   "metadata": {
    "id": "adb65b9b"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "prefixes = [ss for ss in nlp.Defaults.prefixes if '<' not in ss]\n",
    "prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
    "nlp.tokenizer.prefix_search = prefix_regex.search\n",
    "\n",
    "suffixes = [ss for ss in nlp.Defaults.suffixes if '>' not in ss]\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "\n",
    "def tokenize(text):\n",
    "    ''' Since it is a language model, we don't need to remove the stop words.\n",
    "    '''\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62677517",
   "metadata": {
    "id": "aa948370"
   },
   "source": [
    "## 1. N-gram (50 points)\n",
    "In this section, you are required to implement an N-gram model for language modeling and two smoothing methods.\n",
    "1. Implement N-gram (Bigram).\n",
    "2. Implement Good Turing smoothing.\n",
    "3. Implement Kneser-Ney smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6efe6ac",
   "metadata": {
    "id": "79930b64"
   },
   "source": [
    "### 1.1 Implement a bigram for language modeling (fill the code, 10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b362771",
   "metadata": {
    "id": "85044a64"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class BiGram(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Construction function of BiGram.\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "        '''\n",
    "\n",
    "        self.uni_count = defaultdict(lambda: 0)\n",
    "        self.bi_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        \n",
    "        \n",
    "    def fit(self, texts):\n",
    "        self._unigram_count(texts)\n",
    "        self._bigram_count(texts)\n",
    "        \n",
    "    \n",
    "    def _unigram_count(self, texts):\n",
    "        ''' Count tokens, and store in self.uni_count\n",
    "            Input\n",
    "                texts: a list of text\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        freq_count = None\n",
    "        for text in tqdm(texts, total=len(texts)):\n",
    "            freq_count = Counter(tokenize(preprocesser.apply(text.strip()))) if freq_count is None else freq_count + Counter(tokenize(preprocesser.apply(text.strip())))\n",
    "        self.uni_count = defaultdict(lambda: 0, freq_count)\n",
    "        ### End\n",
    "            \n",
    "    \n",
    "    \n",
    "    def _bigram_count(self, texts):\n",
    "        ''' Count tokens in bigram way, and store in self.bi_count\n",
    "            Input\n",
    "                texts: a list of text\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        for text in tqdm(texts, total=len(texts)):\n",
    "            tokens = tokenize(preprocesser.apply(text.strip()))\n",
    "            for i in range(len(tokens[:-1])):\n",
    "                self.bi_count[tokens[i]][tokens[i+1]] += 1\n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two tokens, calculate the bigram probability\n",
    "            Input\n",
    "                w1: the first token of bigram\n",
    "                w2: the second token of bigram\n",
    "        '''\n",
    "        prob = 0.\n",
    "        \n",
    "        ### Start you code\n",
    "        try:\n",
    "            prob = self.bi_count[w1][w2]/self.uni_count[w1]\n",
    "        except ZeroDivisionError:\n",
    "            prob = 1E-2\n",
    "        ### End\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        w_next = None\n",
    "        \n",
    "        ### Start your code\n",
    "        w_next = sorted(self.bi_count[w].items(), key=lambda x:x[1], reverse=True)[0][0]\n",
    "\n",
    "        \n",
    "        ### End\n",
    "        \n",
    "        return w_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba174212",
   "metadata": {
    "id": "bdd9a515"
   },
   "source": [
    "### 1.2 Implement Good Turing smoothing (fill the code, 15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4a0218",
   "metadata": {
    "id": "94009b7e"
   },
   "outputs": [],
   "source": [
    "class GoodTuring(object):\n",
    "    \n",
    "    def __init__(self, bigram):\n",
    "        ''' Construction function of Good Turing.\n",
    "            Input\n",
    "                bigram: Bigram model\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "                -----------------\n",
    "                For bigram\n",
    "                bi_nc: a dictionary with default value 0, the count of things we've seen c times.\n",
    "                bi_c_star: (c+1)*N_c+1 / N_c, page 64 of slides (lecture 5).\n",
    "                bi_N: \\sum c*N_c, page 64 of slides (lecture 5).\n",
    "                \n",
    "                For unigram\n",
    "                uni_nc: a dictionary with default value 0, the count of things we've seen c times.\n",
    "                uni_c_star: (c+1)*N_c+1 / N_c, page 64 of slides (lecture 5).\n",
    "                uni_N: \\sum c*N_c, page 64 of slides (lecture 5).\n",
    "            \n",
    "        '''\n",
    "        self.uni_count = bigram.uni_count\n",
    "        self.bi_count = bigram.bi_count\n",
    "        \n",
    "        self.uni_nc = defaultdict(lambda: 0)\n",
    "        self.bi_nc = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.uni_c_star = defaultdict(lambda: 0)\n",
    "        self.bi_c_star = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.uni_N = 0\n",
    "        self.bi_N = 0\n",
    "        \n",
    "        \n",
    "    def fit(self, texts):\n",
    "        self._calc_N_c()\n",
    "        self._calc_c_star_and_N()\n",
    "        \n",
    "    \n",
    "    def _calc_N_c(self):\n",
    "        ''' Count the frequency of frequency c, and store to self.nc.\n",
    "            Page 64 of slides (lecture 5)\n",
    "            Hint: You could directly utililze self.bi_count and self.uni_count to calculate N_c\n",
    "        '''\n",
    "        \n",
    "        ### Start you code\n",
    "        self.uni_nc = defaultdict(lambda: 0, Counter(self.uni_count.values()))\n",
    "        temp = Counter()\n",
    "        for i in self.bi_count.values():\n",
    "            temp += Counter(i.values())\n",
    "        self.bi_nc = defaultdict(lambda: 0, temp)\n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def _calc_c_star_and_N(self):\n",
    "        ''' Calculate c_star and N. (page 65 of slides (lecture 5))\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        # c_list = list(self.uni_nc.keys())\n",
    "        for c in range(max(self.uni_nc.keys())): \n",
    "            try:\n",
    "                self.uni_c_star[c] = (c + 1)*(self.uni_nc[c + 1]) / self.uni_nc[c]\n",
    "                self.uni_N += c*self.uni_nc[c]\n",
    "            except:\n",
    "                continue\n",
    "        for c in range(max(self.bi_nc.keys())):\n",
    "            try:\n",
    "                self.bi_c_star[c] = (c + 1)*(self.bi_nc[c + 1]) / self.bi_nc[c]\n",
    "                self.bi_N += c*self.bi_nc[c]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two words, calculate the GT probability\n",
    "                p_GT = c_star / N, if c != 0\n",
    "                p_GT = N_1 / N, if c = 0\n",
    "                \n",
    "                p = p_GT(w1, w2) / p_GT(w1)\n",
    "                \n",
    "            Input\n",
    "                w1: the first word\n",
    "                w2: the second word\n",
    "                \n",
    "        '''\n",
    "        prob = 0.\n",
    "        \n",
    "        ### Start you code\n",
    "        c_bi = self.bi_count[w1][w2]\n",
    "        bi_p_GT = self.bi_c_star[c_bi]/self.bi_N if c_bi == 0 else self.bi_nc[c_bi]/self.bi_N\n",
    "\n",
    "        c_uni = self.uni_count[w1]\n",
    "        uni_p_GT = self.uni_c_star[c_uni]/self.uni_N if c_uni == 0 else self.uni_nc[1]/self.uni_N\n",
    "  \n",
    "        prob = bi_p_GT/uni_p_GT\n",
    "        ### End\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        w_next = None\n",
    "        \n",
    "        ### Start your code\n",
    "        w_next_list = list(self.bi_count[w].keys())\n",
    "        prob_list = []\n",
    "        for w2 in w_next_list:\n",
    "            prob_list.append(self.probability(w, w2))\n",
    "        w_next = w_next_list[np.argmax(prob_list)]\n",
    "        ### End\n",
    "        \n",
    "        return w_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c743612",
   "metadata": {
    "id": "a4c2d2c3"
   },
   "source": [
    "### 1.3 Implement Kneser-Ney smoothing (fill the code, 15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae91d54b",
   "metadata": {
    "id": "0173537e"
   },
   "outputs": [],
   "source": [
    "class KneserNey(object):\n",
    "    \n",
    "    def __init__(self, bigram, d=0.75):\n",
    "        ''' Construction function of KneserNey.\n",
    "            Params:\n",
    "                uni_count: a dictionary with default value 0\n",
    "                bi_count: a dictionary that each value is a dictionary with default value 0\n",
    "                -----------------\n",
    "                num_bigram_types: page 73 of slides (lecture 5)\n",
    "                novel_continuation: \\{ w_{i-1}: c(w_{i-1}, w) \\}, page 73 of slides (lecture 5)\n",
    "                p_continuation: page 73 of slides (lecture 5)\n",
    "                novel_previous: \\{ w: c(w_{i-1}, w) \\}, page 75 of slides (lecture 5)\n",
    "                lam: page 75 of slides (lecture 5)\n",
    "                d: 0.75\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        self.uni_count = bigram.uni_count\n",
    "        self.bi_count = bigram.bi_count\n",
    "        \n",
    "        self.num_bigram_types = 0\n",
    "        self.novel_continuation = defaultdict(lambda: 0)\n",
    "        self.novel_previous = defaultdict(lambda: 0)\n",
    "        self.p_continuation = defaultdict(lambda: 0)\n",
    "        self.lam = defaultdict(lambda: 0)\n",
    "        \n",
    "        self.d = d\n",
    "        \n",
    "    \n",
    "    def fit(self, texts):\n",
    "        self._calc_num_bigram_types()\n",
    "        self._calc_novel_continuation_and_novel_previous()\n",
    "        self._calc_P_continuation()\n",
    "        self._calc_lambda()\n",
    "        \n",
    "    \n",
    "    def _calc_num_bigram_types(self):\n",
    "        ''' Calculate the number of bigram types, and store in self.num_bigram_types\n",
    "            page 73 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the bigram count (self.bi_count) which is obtained from Bigram model.\n",
    "        '''\n",
    "        \n",
    "        ### Start your code                    \n",
    "        for w1 in tqdm(self.bi_count.keys(), desc = 'calculating bigram_types',total = len(self.bi_count.keys())):\n",
    "            for w2,freq in self.bi_count[w1].items():\n",
    "                if freq != 0:\n",
    "                    self.num_bigram_types += 1\n",
    "        ### End\n",
    "      \n",
    "    \n",
    "    def _calc_novel_continuation_and_novel_previous(self):\n",
    "        ''' Calculate novel continuation, and novel previous, \n",
    "            and store them in self.novel_continuation and self.novel_previous\n",
    "            \n",
    "            novel_continuation = \\{ w_{i-1}: c(w_{i-1}, w) \\}, page 73 of slides (lecture 5)\n",
    "            novel_previous = \\{ w: c(w_{i-1}, w) \\}, page 75 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the bigram count (self.bi_count) which obtained from Bigram model.\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        w1_list = list(self.bi_count.keys())\n",
    "        \n",
    "        for w1 in tqdm(w1_list, desc='novel_continuation', total=len(w1_list)):\n",
    "            self.novel_continuation[w1] = len([i for i in self.bi_count[w1].values() if i != 0])\n",
    "            \n",
    "        w2_list = list(self.uni_count.keys())\n",
    "        \n",
    "        for w2 in tqdm(w2_list, desc='novel_previous', total=len(w2_list)):\n",
    "            for w1 in w1_list:\n",
    "                if self.bi_count[w1][w2] != 0:\n",
    "                    self.novel_previous[w1] += 1\n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def _calc_P_continuation(self):\n",
    "        ''' Calculate p continuation, and store in self.p_continuation.\n",
    "            page 73 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the novel continuation (self.novel_continuation).\n",
    "        '''\n",
    "        \n",
    "        ### Start your code \n",
    "        w_list = list(self.novel_continuation.keys())\n",
    "        for w in tqdm(w_list,desc='p_continuation',total=len(w_list)):\n",
    "            try:\n",
    "                self.p_continuation[w] = self.novel_continuation[w] / self.num_bigram_types\n",
    "            except:\n",
    "                self.p_continuation[w] = self.novel_continuation[w]        \n",
    "        ### End\n",
    "    \n",
    "    \n",
    "    def _calc_lambda(self):\n",
    "        ''' Calculate lambda, and store in self.lam.\n",
    "            page 75 of slides (lecture 5)\n",
    "            \n",
    "            Hint: you could utilize the novel previous (self.novel_previous) and unigram (self.uni_count).\n",
    "        '''\n",
    "        \n",
    "        ### Start your code\n",
    "        w1_list = list(self.bi_count.keys())\n",
    "        for w1 in w1_list:\n",
    "            try:\n",
    "                self.lam[w1] = (self.d / self.uni_count[w1]) * (len(self.bi_count[w1]))\n",
    "            except:\n",
    "                self.lam[w1] = (self.d) * (len(self.bi_count[w1]))\n",
    "        ### End\n",
    "        \n",
    "        \n",
    "    def probability(self, w1, w2):\n",
    "        ''' Given two words, calculate the KN probability\n",
    "            Page 74 of slides (lecture 5)\n",
    "                \n",
    "            Input\n",
    "                w1: the first word\n",
    "                w2: the second word\n",
    "        '''\n",
    "        \n",
    "        prob = 0.\n",
    "        \n",
    "        # Start your code\n",
    "        try:\n",
    "            prob = (max(self.bi_count[w1][w2] - self.d, 0)/self.uni_count(w1)) + (self.lam[w1] * self.p_continuation[w2])\n",
    "        except:\n",
    "            prob = (max(self.bi_count[w1][w2] - self.d, 0)) + (self.lam[w1] * self.p_continuation[w2])\n",
    "        # End\n",
    "            \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def predict(self, w):\n",
    "        ''' Given a word, find a word with the highest probability\n",
    "            Input\n",
    "                w: a word\n",
    "                \n",
    "            Hint: utilize self.probability(w, w2) to find which w2 has the highest probability\n",
    "        '''\n",
    "        \n",
    "        pred = ''\n",
    "        \n",
    "        ### Start your code\n",
    "        w_next_list = list(self.bi_count[w].keys())\n",
    "        prob_list = []\n",
    "        for w2 in w_next_list:\n",
    "            prob_list.append(self.probability(w, w2))\n",
    "        pred = w_next_list[np.argmax(prob_list)]\n",
    "        ### End\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eefe96",
   "metadata": {
    "id": "4d622210"
   },
   "source": [
    "### 1.4 Implement Perplexity (fill the code, 10 point)\n",
    "**Hint:** Multiplication of probabilities may lead to an overflow problem. One trick is to move the computation to the logarithm space. Therefore, you could use summation instead of multiplication to calculate perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d758a6",
   "metadata": {
    "id": "651d873e"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def perplexity(model, texts):\n",
    "    ''' Calculate the perplexity score.\n",
    "        Inputs\n",
    "            model: the model you want to evaluate (BiGram, GoodTuring, or KneserNey)\n",
    "            texts: a list of validation text\n",
    "        Output\n",
    "            perp: the perplexity of the model on texts\n",
    "    '''\n",
    "    perp = 1.\n",
    "    \n",
    "    ### Start your code\n",
    "\n",
    "    prob_array = []\n",
    "    for text in texts:\n",
    "        tokens = tokenize(preprocesser.apply(text.strip()))\n",
    "        for i in range(len(tokens)-1):\n",
    "            prob = model.probability(tokens[i],tokens[i+1])\n",
    "            prob = 1E-1 if prob == 0 else prob\n",
    "            prob_array.append(prob)\n",
    "    perp = np.exp(-np.mean(np.log(prob_array)))\n",
    "\n",
    "    ### End\n",
    "    \n",
    "    return perp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c7560",
   "metadata": {
    "id": "1ae9b9bc"
   },
   "source": [
    "### 1.5 Calculate the perplexity of three models\n",
    "\n",
    "Run the following cell to obtian the perplexity of BiGram, Good Turing, and Kneser-Ney.\n",
    "\n",
    "**Note that, the perlexity should be less than 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1701c4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "e69bba41e3384f19be77eb2e870ac131",
      "92d196ac95b34d0a9b85fde8c291c863",
      "c6971f8d9554424c90a42d04cbb42579",
      "75ad4c14843d41a18298b4580ac79663",
      "b3518c5087a54b8e90271e5960d91865",
      "b2df758ccb7c4ce2ae4ace0d60567536",
      "61d7f90ab5d140c48dc3dd199b6acf75",
      "0afd68d6cc3e452b9995c16b45498e0c",
      "aa61fe57992243f581ae3a2be486164c",
      "ffd343e5537b411e821e1c7d1b40fd57",
      "728ff942c62e4316bee3712f83be0d4f"
     ]
    },
    "id": "9b561642",
    "outputId": "25ca5b99-2202-4d9d-c284-4a355792a850"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9f1a60db84442790616facc7da85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\.conda\\envs\\nlp\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889a1e8a505749dc927e2de4fe5897db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Bigram is: 43.6457\n"
     ]
    }
   ],
   "source": [
    "# Train Bigram\n",
    "bigram = BiGram()\n",
    "bigram.fit(train_texts)\n",
    "\n",
    "# Perplexity\n",
    "bigram_perplexity = perplexity(bigram, valid_texts)\n",
    "print(f'The perplexity of Bigram is: {bigram_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f615770",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "9a53da36e76a4c078ec997f7ecb19c53",
      "96df479f4bce49a6ad50823ca13c7a8a",
      "1f3cad8f4790440991d8689a6901092b",
      "7f5cad4515454ac1b3cf13bafe2be8b7",
      "dcf79d8ac613425fa5680359fcd55e52",
      "3348deeabd834cc8af78d259c5d264eb",
      "eef62927dca744b0b0ac405a69077e1d",
      "661ea4ef6e4c46e4930a9fe6622e15b6",
      "76435fd43d15403aa6ae09c170d08bff",
      "5eac3a9da9574e898c0c10b93577b244",
      "1e5cbadd09154cae8aa3ed9cffccaecf",
      "c63c7845afb448adb5e2b791aa6711f2",
      "b86c1938fbf54e1f9ec838d22ac8e686",
      "3f98bb7355c8445c8e6f533c010723df",
      "f7105aa135ab48fb8ba43a3b6df554a8",
      "3545d285dd56410eb867b6bddd64bbfb",
      "1c400992df144367acc8f1684428f24e",
      "554d18a1a4d846b184aa00cbc93a5578",
      "93d68d9d5ae64d3cb21e70b9e60dad35",
      "a83a2f6476014b699354aeec51081856",
      "589fdc916f904eb8a2c14cde025eee02",
      "798c1eca83ef4409ad5cf05ead9a55c0"
     ]
    },
    "id": "5ffee5d5",
    "outputId": "ff739636-703b-40dc-b185-dbfd0ce77d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Good Turing is: 0.2939\n"
     ]
    }
   ],
   "source": [
    "# Train Good Turing\n",
    "gt = GoodTuring(bigram)\n",
    "gt.fit(train_texts)\n",
    "\n",
    "# Perplexity\n",
    "gt_perplexity = perplexity(gt, valid_texts)\n",
    "print(f'The perplexity of Good Turing is: {gt_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64267d1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b00b6b54679a43b3bdc1259ad6f0e8b0",
      "d05c534b93d24537924364b5e0f90e41",
      "eeb84b4f6bea45a6bcadd12e6a68ee83",
      "aebb9ebcf3f642d1ab1cbdc27dc4765c",
      "da209ecaa8af40e6b771ec773a4596e4",
      "f7f1f75e05d34717ba63436a403541d4",
      "9a8be20f7afd48a38aaaac982a3e020b",
      "7e51e710fe314164bd358efa9f7c553e",
      "08888abc179e4f4db80b340adf3cefc4",
      "546564a20a2243c1a901562e6e16357e",
      "82188772d1a64ddfbf2b18049e8991f0"
     ]
    },
    "id": "28e36676",
    "outputId": "0956a545-979e-42c2-8b0f-91bc0dc6bfa8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b776ba3dbf14f768b7ec57acec83cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating bigram_types:   0%|          | 0/9892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be80384412b45f0b23f782c602d148d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "novel_continuation:   0%|          | 0/9892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c6d29832cb42a4b6ca84404ee35c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "novel_previous:   0%|          | 0/9893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9cd9499904881bb6b76bd831edfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "p_continuation:   0%|          | 0/9892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of Kneser-Ney is: 0.1660\n"
     ]
    }
   ],
   "source": [
    "# For Kneser-Ney\n",
    "kn = KneserNey(bigram, d=0.75)\n",
    "kn.fit(train_texts)\n",
    "\n",
    "# Perplexity\n",
    "kn_perplexity = perplexity(kn, valid_texts)\n",
    "print(f'The perplexity of Kneser-Ney is: {kn_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88862df",
   "metadata": {
    "id": "a6438a7d"
   },
   "source": [
    "### 1.6 Use N-gram model make predictions\n",
    "\n",
    "Run the following cells to see how your models work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb02c9",
   "metadata": {},
   "source": [
    "#### 1.6.1 Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdde31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> investors taking this as a sign that a broad industry ___, prediction: </s>\n",
      "1 ==> the subcommittee congress and the american public have every right ___, prediction: to\n",
      "2 ==> they hope the foreign deals will divide the hollywood opposition ___, prediction: to\n",
      "3 ==> robert h. <unk> an economist for lloyd 's bank in ___, prediction: the\n",
      "4 ==> but mr. butcher 's comments make one thing clear some ___, prediction: of\n",
      "5 ==> canada 's current oil exports to the u.s. total about ___, prediction: n\n",
      "6 ==> a second <unk> plant at uncle sam <unk> that produces ___, prediction: <unk>\n",
      "7 ==> the monthly increase is the highest recorded in the past ___, prediction: n\n",
      "8 ==> but senate supporters of the <unk> legislation said that other ___, prediction: <unk>\n",
      "9 ==> giant has n't ever disclosed the proposed price although <unk> ___, prediction: <unk>\n",
      "10 ==> lexus sales were n't available the cars are imported and ___, prediction: <unk>\n",
      "11 ==> once again the specialists were not able to handle the ___, prediction: <unk>\n",
      "12 ==> for example the new york state counsel for the <unk> ___, prediction: <unk>\n",
      "13 ==> mr. <unk> said <unk> will also mark its portfolio of ___, prediction: the\n",
      "14 ==> generally overcapacity in commercial real estate is dropping from its ___, prediction: <unk>\n",
      "15 ==> <unk> & <unk> of houston and <unk> robertson fraser & ___, prediction: <unk>\n",
      "16 ==> the $ N billion california public employees retirement system for ___, prediction: the\n",
      "17 ==> the big three 's <unk> for deregulation began <unk> in ___, prediction: the\n",
      "18 ==> hammond co. newport beach calif. said fidelity national financial inc. ___, prediction: </s>\n",
      "19 ==> executives at prudential-bache securities inc. a backer spielvogel client that ___, prediction: the\n",
      "20 ==> giant a beverly hills calif. collection of companies that is ___, prediction: a\n",
      "21 ==> both sides are to sit down next month for yet ___, prediction: to\n",
      "22 ==> today could even be an up day mr. davis says ___, prediction: </s>\n",
      "23 ==> the former president and chief executive eric w. <unk> resigned ___, prediction: as\n",
      "24 ==> off and on since then the companies have <unk> in ___, prediction: the\n",
      "25 ==> richard p. <unk> formerly eastern airlines ' top lawyer joined ___, prediction: the\n",
      "26 ==> in the N third quarter quantum earned $ N million ___, prediction: or\n",
      "27 ==> these high <unk> took a big <unk> today he said ___, prediction: </s>\n",
      "28 ==> it said analysts had been expecting a small profit for ___, prediction: the\n",
      "29 ==> cbs inc. is cutting the pat <unk> show down to ___, prediction: n\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = bigram.predict(tokens[-2])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60937816",
   "metadata": {},
   "source": [
    "#### 1.6.2 Good Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7759ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> in a related development the <unk> for the fourth year ___, prediction: casting\n",
      "1 ==> this is n't a change in government policy this provision ___, prediction: initially\n",
      "2 ==> mrs. <unk> said her <unk> investment club 's portfolio lost ___, prediction: more\n",
      "3 ==> to fend off sir james 's advances b.a.t has proposed ___, prediction: lower\n",
      "4 ==> the chinese leaders have to decide whether they want control ___, prediction: point\n",
      "5 ==> see related story fed ready to <unk> big funds wsj ___, prediction: business\n",
      "6 ==> but even among those aged N and older the share ___, prediction: data\n",
      "7 ==> brazil and venezuela are the only two countries that have ___, prediction: memory\n",
      "8 ==> japanese stocks dropped early monday but by late morning were ___, prediction: exposed\n",
      "9 ==> and even if a <unk> would wear flowers in her ___, prediction: eyes\n",
      "10 ==> seven big board stocks ual amr bankamerica walt disney capital ___, prediction: may\n",
      "11 ==> alan <unk> executive vice president of investment canada which oversees ___, prediction: n\n",
      "12 ==> should sales continue to be strong through the christmas season ___, prediction: which\n",
      "13 ==> he recommends that investors sell <unk> stocks but hang on ___, prediction: smokers\n",
      "14 ==> the N crash brought the reagan administration and democratic lawmakers ___, prediction: representing\n",
      "15 ==> newport corp. said it expects to report <unk> earnings of ___, prediction: consolidated\n",
      "16 ==> such legislation must be enacted by the end of the ___, prediction: imported\n",
      "17 ==> stocks that were thrown out just on an emotional basis ___, prediction: being\n",
      "18 ==> the parent companies forecast sales for the venture of around ___, prediction: at\n",
      "19 ==> the mmi and the s&p N are the two major ___, prediction: speech\n",
      "20 ==> we believe they could <unk> perhaps two to three billion ___, prediction: kent\n",
      "21 ==> in one wild hour of trading the market managed to ___, prediction: edison\n",
      "22 ==> we are <unk> for all the news says mr. <unk> ___, prediction: lung\n",
      "23 ==> mr. <unk> <unk> to launch an ambitious but <unk> $ ___, prediction: lung\n",
      "24 ==> there is an underlying concern on the part of the ___, prediction: imported\n",
      "25 ==> britain 's government plans to raise about # N billion ___, prediction: kent\n",
      "26 ==> the company said a drop in activity in the <unk> ___, prediction: lung\n",
      "27 ==> the company said the improvement is related to additional <unk> ___, prediction: lung\n",
      "28 ==> $ N million of stripped mortgage securities underwritten by <unk> ___, prediction: lung\n",
      "29 ==> in his article mr. <unk> who was in europe last ___, prediction: fewer\n"
     ]
    }
   ],
   "source": [
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = gt.predict(tokens[-2])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2bee3",
   "metadata": {},
   "source": [
    "#### 1.6.3 Kneser-Ney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222090ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e72a4613",
    "outputId": "145ecc65-b652-4a99-d4d7-da89a4212be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> among classes for which details were available yields ranged from ___, prediction: n\n",
      "1 ==> some lagging competitors even may leave the personal computer business ___, prediction: </s>\n",
      "2 ==> <unk> <unk> of anc and <unk> we <unk> shook the ___, prediction: <unk>\n",
      "3 ==> the company was officially merged with bristol-myers co. earlier this ___, prediction: year\n",
      "4 ==> richard p. <unk> formerly eastern airlines ' top lawyer joined ___, prediction: the\n",
      "5 ==> the competitive spirit is clearly <unk> radio free europe which ___, prediction: is\n",
      "6 ==> <unk> percent do n't even feel they are financially well ___, prediction: as\n",
      "7 ==> its strategy in the past has been to serve as ___, prediction: a\n",
      "8 ==> since then life has changed a lot for <unk> leonard ___, prediction: <unk>\n",
      "9 ==> we could n't get dealers to answer their phones said ___, prediction: </s>\n",
      "10 ==> in these four for instance the rtc is stuck with ___, prediction: the\n",
      "11 ==> the <unk> radio reporters seem better informed and more critical ___, prediction: to\n",
      "12 ==> in the same month the office of thrift supervision ordered ___, prediction: the\n",
      "13 ==> six of the N midwestern states have been growing steadily ___, prediction: <unk>\n",
      "14 ==> under the latest offer hk$ N million us$ N million ___, prediction: or\n",
      "15 ==> and there was much criticism of the new york stock ___, prediction: exchange\n",
      "16 ==> but senate supporters of the <unk> legislation said that other ___, prediction: <unk>\n",
      "17 ==> various evidence including a <unk> institution study of some N ___, prediction: n\n",
      "18 ==> kenneth j. <unk> who was named president of this thrift ___, prediction: supervision\n",
      "19 ==> this month however businessland warned investors that results for its ___, prediction: <unk>\n",
      "20 ==> for instance <unk> co. posted an N N gain in ___, prediction: the\n",
      "21 ==> further <unk> the <unk> audience is the addition of the ___, prediction: <unk>\n",
      "22 ==> the share of minorities in those positions has risen to ___, prediction: n\n",
      "23 ==> would the program be run by the federal government by ___, prediction: the\n",
      "24 ==> if mr. <unk> becomes the major opposition leader he could ___, prediction: be\n",
      "25 ==> the benchmark 30-year treasury bond was quoted N p.m. edt ___, prediction: <unk>\n",
      "26 ==> it involves accepting risk or giving up income or deferring ___, prediction: <unk>\n",
      "27 ==> financial corp. said it agreed to buy the bonds after ___, prediction: the\n",
      "28 ==> in addition the companion deficit-reduction bill already passed by the ___, prediction: <unk>\n",
      "29 ==> for balance and in hopes of gaining some <unk> <unk> ___, prediction: <unk>\n"
     ]
    }
   ],
   "source": [
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    clean_text = preprocesser.apply(text)\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = kn.predict(tokens[-2])\n",
    "    print(f'{i} ==> {text.strip()}, prediction: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a539c8",
   "metadata": {
    "id": "6d1cf523"
   },
   "source": [
    "## 2. RNN (50 points)\n",
    "In this section, you are required to implement an RNN-based language model. **Libraries are allowed in this section, such as PyTorch or TensorFlow**. And, of course, you could implement the model from scratch which will get extra credits. \n",
    "\n",
    "I divided the whole process into several steps.\n",
    "1. Initialize parameters\n",
    "2. Prepare Data\n",
    "3. Implement the model\n",
    "4. Train your model\n",
    "5. Evaluate your model\n",
    "\n",
    "Please note that you could change those steps by your needs. As long as you correctly implement the model and have reasonable results you will get full points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87352ca4",
   "metadata": {
    "id": "b696ab8c"
   },
   "source": [
    "### 2.1 Initialize parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66b31af3",
   "metadata": {
    "id": "c11c8846"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                                                     #\n",
    "#        Change the default values accordingly        #\n",
    "#                                                     #\n",
    "#######################################################\n",
    "\n",
    "learning_rate = 1E-3\n",
    "batch_size = 50\n",
    "hidden_size = 100\n",
    "embedding_size = 200\n",
    "num_epochs = 30\n",
    "window_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fadcea3",
   "metadata": {
    "id": "b96cd8d0"
   },
   "source": [
    "### 2.2 Data preparation (Fill the code: 5 points)\n",
    "\n",
    "Here is what do you might need to do in this section:\n",
    "1. Build a vocabulary.\n",
    "2. Prepare the training data.\n",
    "3. Prepare the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1f0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57bc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.preprocessor = Preprocesser()\n",
    "        self.word2freq = Counter()\n",
    "        self.word2idx = defaultdict(lambda: 0)\n",
    "\n",
    "    def making_idx(self):\n",
    "        self.unique_tokens = self.word2freq.keys()\n",
    "        self.vocab_size = len(self.unique_tokens)\n",
    "        for i,j in enumerate(self.unique_tokens):\n",
    "            self.word2idx[j] = i+1\n",
    "        \n",
    "    def fit_on_texts(self, texts):\n",
    "        for doc in tqdm(texts):\n",
    "            self.word2freq += Counter(tokenize(self.preprocessor.apply(doc.strip())))\n",
    "        self.making_idx()\n",
    "\n",
    "    def texts_to_sequences(self, sentence):\n",
    "        tokens = tokenize(self.preprocessor.apply(sentence.strip()))\n",
    "        return list(map(lambda x: self.word2idx[x] if x in self.unique_tokens else self.word2idx['<unk>'], tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c2dbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65d6bfa22fd4e58a3be41d81bbac502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415900db749b48d6b18dc595844da041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c3779760f46b3a9567128d4583aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_input_sequences = []\n",
    "for line in tqdm(train_texts, total=len(train_texts)):\n",
    "    token_list = tokenizer.texts_to_sequences(line)\n",
    "    for i in range(1, len(token_list)):\n",
    "        train_input_sequences.append(token_list[:i+1][-(window_size+1):])\n",
    "\n",
    "train_input_sequences = pad_sequences(train_input_sequences, maxlen=window_size+1)\n",
    "\n",
    "val_input_sequences = []\n",
    "for line in tqdm(valid_texts, total=len(valid_texts)):\n",
    "    token_list = tokenizer.texts_to_sequences(line)\n",
    "    for i in range(1, len(token_list)):\n",
    "        val_input_sequences.append(token_list[:i+1][-(window_size+1):])\n",
    "\n",
    "val_input_sequences = pad_sequences(val_input_sequences, maxlen=window_size+1)\n",
    "\n",
    "X_train = train_input_sequences[:,:-1]\n",
    "labels_train = train_input_sequences[:,-1]\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(labels_train, num_classes=tokenizer.vocab_size+1, dtype='float32')\n",
    "\n",
    "X_val = val_input_sequences[:,:-1]\n",
    "labels_val = val_input_sequences[:,-1]\n",
    "Y_val = tf.keras.utils.to_categorical(labels_val, num_classes=tokenizer.vocab_size+1, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aed2d3",
   "metadata": {
    "id": "2f3832aa"
   },
   "source": [
    "### 2.3 Build your model (Fill the code: 10 points)\n",
    "\n",
    "\n",
    "Here is what do you might need to do in this section:\n",
    "1. Create a model.\n",
    "2. Add an embedding layer as the first layer.\n",
    "3. Add a RNN cell (GRU or LSTM) as the next layer.\n",
    "4. Add a output layer.\n",
    "5. Given a sequence words, for each word, predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814e3ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 200)           1978800   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9894)              1988694   \n",
      "=================================================================\n",
      "Total params: 4,208,294\n",
      "Trainable params: 4,208,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(tokenizer.vocab_size+1, embedding_size, input_length=window_size))\n",
    "model.add(Bidirectional(LSTM(hidden_size)))\n",
    "model.add(Dense(tokenizer.vocab_size+1, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cbcf4",
   "metadata": {
    "id": "a0cbf03a"
   },
   "source": [
    "### 2.4 Setup the training step and train the model (Fill the code: 10 points)\n",
    "Based on your implementation, setup your training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "837b7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18405/18405 [==============================] - 1797s 98ms/step - loss: 5.5380 - accuracy: 0.1804 - val_loss: 5.1937 - val_accuracy: 0.2099\n",
      "Epoch 2/30\n",
      "18405/18405 [==============================] - 1798s 98ms/step - loss: 4.9040 - accuracy: 0.2311 - val_loss: 5.0116 - val_accuracy: 0.2267\n",
      "Epoch 3/30\n",
      "18405/18405 [==============================] - 1788s 97ms/step - loss: 4.6219 - accuracy: 0.2520 - val_loss: 4.9666 - val_accuracy: 0.2331\n",
      "Epoch 4/30\n",
      "18405/18405 [==============================] - 1790s 97ms/step - loss: 4.4242 - accuracy: 0.2670 - val_loss: 4.9765 - val_accuracy: 0.2359\n",
      "Epoch 5/30\n",
      "18405/18405 [==============================] - 1634s 89ms/step - loss: 4.2637 - accuracy: 0.2793 - val_loss: 5.0132 - val_accuracy: 0.2338\n",
      "Epoch 6/30\n",
      "18405/18405 [==============================] - 1610s 87ms/step - loss: 4.1288 - accuracy: 0.2907 - val_loss: 5.0616 - val_accuracy: 0.2347\n",
      "Epoch 7/30\n",
      "18405/18405 [==============================] - 1619s 88ms/step - loss: 4.0140 - accuracy: 0.3002 - val_loss: 5.1189 - val_accuracy: 0.2324\n",
      "Epoch 8/30\n",
      "18405/18405 [==============================] - 1674s 91ms/step - loss: 3.9160 - accuracy: 0.3093 - val_loss: 5.1662 - val_accuracy: 0.2302\n",
      "Epoch 9/30\n",
      "18405/18405 [==============================] - 1730s 94ms/step - loss: 3.8318 - accuracy: 0.3175 - val_loss: 5.2296 - val_accuracy: 0.2283\n",
      "Epoch 10/30\n",
      "18405/18405 [==============================] - 1730s 94ms/step - loss: 3.7570 - accuracy: 0.3252 - val_loss: 5.2697 - val_accuracy: 0.2267\n",
      "Epoch 11/30\n",
      "18405/18405 [==============================] - 1709s 93ms/step - loss: 3.6948 - accuracy: 0.3313 - val_loss: 5.3259 - val_accuracy: 0.2246\n",
      "Epoch 12/30\n",
      "18405/18405 [==============================] - 1682s 91ms/step - loss: 3.6402 - accuracy: 0.3378 - val_loss: 5.3700 - val_accuracy: 0.2230\n",
      "Epoch 13/30\n",
      "18405/18405 [==============================] - 1657s 90ms/step - loss: 3.5952 - accuracy: 0.3425 - val_loss: 5.4210 - val_accuracy: 0.2211\n",
      "Epoch 14/30\n",
      "18405/18405 [==============================] - 1639s 89ms/step - loss: 3.5549 - accuracy: 0.3474 - val_loss: 5.4611 - val_accuracy: 0.2212\n",
      "Epoch 15/30\n",
      "18405/18405 [==============================] - 1623s 88ms/step - loss: 3.5203 - accuracy: 0.3520 - val_loss: 5.5034 - val_accuracy: 0.2198\n",
      "Epoch 16/30\n",
      "18405/18405 [==============================] - 1622s 88ms/step - loss: 3.4884 - accuracy: 0.3553 - val_loss: 5.5290 - val_accuracy: 0.2173\n",
      "Epoch 17/30\n",
      "18405/18405 [==============================] - 1644s 89ms/step - loss: 3.4647 - accuracy: 0.3584 - val_loss: 5.5569 - val_accuracy: 0.2168\n",
      "Epoch 18/30\n",
      " 5139/18405 [=======>......................] - ETA: 18:20 - loss: 3.2546 - accuracy: 0.384"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1103\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m       logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m       end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1103\u001b[0m       \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(logs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# Run validation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:440\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 440\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:289\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 289\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:309\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    307\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    312\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:342\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 342\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:961\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 961\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1017\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1015\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m   logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39mto_numpy_or_python_type(logs)\n\u001b[1;32m-> 1017\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:575\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    573\u001b[0m prev_total_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_width\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamic_display:\n\u001b[1;32m--> 575\u001b[0m   \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\b\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprev_total_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m   sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:541\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 541\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:451\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:216\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     f()\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\zmq\\sugar\\socket.py:547\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    540\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    541\u001b[0m             data,\n\u001b[0;32m    542\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    543\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    544\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    545\u001b[0m         )\n\u001b[0;32m    546\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSocket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:718\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:765\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:242\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=num_epochs, verbose=1, batch_size=batch_size, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Bi LSTM Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1fa77",
   "metadata": {
    "id": "9c9ebdc6"
   },
   "source": [
    "### 2.5 Evaluate the model (15 points)\n",
    "Calculate the model's perplexity on the valid set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38dee66",
   "metadata": {
    "id": "f9677797"
   },
   "source": [
    "#### 2.5.1 Deliverable (5 points)\n",
    "Prove\n",
    "<center>$perplexity = exp(\\frac{total\\ loss}{number\\ of\\ predictions})$\n",
    "    \n",
    "*You can either list the steps in the notebook or submit a pdf with all the steps in the submission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc7377",
   "metadata": {
    "id": "JqtbFu_YHTu1"
   },
   "source": [
    "#### 2.5.2 Implement the algorithm to calculate the perplexity of the model. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd8817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "033f5d5d7d254e0eaa9e8248a922cd24",
      "777e888395634af98a54350e9afd3173",
      "23bf828777d6427ca881362636957c1f",
      "1d29f3408a014f69a7e5d422012af3df",
      "79f0039ff69d442fb308d2572e45568e",
      "d1c4dda64d4d4938ac0592eede0af27a",
      "486338a06f9740ddae037dc655a7d18a",
      "5835dc4965724bb29c0f844c1de605a7",
      "dcf4e8ce928244b8b4c07ffe0225fffc",
      "e469615a3ad143318cec11ed6ea82346",
      "73800733b6e549f08c2dc81b292520c4"
     ]
    },
    "id": "20d16e69",
    "outputId": "a04d4c92-9172-414a-e177-2f2881458034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity of RNN based model is: 11.1432\n"
     ]
    }
   ],
   "source": [
    "perp = 0.\n",
    "\n",
    "### Start your code\n",
    "val_data_sequences = []\n",
    "for line in tqdm(valid_texts, total=len(valid_texts)):\n",
    "    token_list = tokenizer.texts_to_sequences(line)\n",
    "    val_data_sequences.append(token_list[-(window_size+1):])\n",
    "\n",
    "val_data_sequences = pad_sequences(val_data_sequences, maxlen=window_size+1)\n",
    "\n",
    "X_val = val_data_sequences[:,:-1]\n",
    "labels_val = val_data_sequences[:,-1]\n",
    "Y_val = tf.keras.utils.to_categorical(labels_val, num_classes=tokenizer.vocab_size+1, dtype='float32')\n",
    "\n",
    "crossentropy_loss = CategoricalCrossentropy()\n",
    "\n",
    "loss = []\n",
    "\n",
    "for i,j in zip(X_val, Y_val):\n",
    "    prediction = model.predict(i.reshape(1,-1))\n",
    "    loss.append(float(crossentropy_loss(j,prediction.reshape(-1))))\n",
    "\n",
    "perp = np.exp(sum(loss)/len(loss))\n",
    "\n",
    "\n",
    "### End\n",
    "\n",
    "print(f'The perplexity of of RNN based model is: {perp:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf08fc",
   "metadata": {
    "id": "e30f87fc"
   },
   "source": [
    "### 2.6 Use RNN language modeling make predictions (10 points)\n",
    "Print the predictions of next words using the RNN model for the same 30 lines of input.txt as in section 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c0ffb8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "d9659bee",
    "outputId": "9ef30f12-d20e-4191-e924-9872bd87b551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> at stake is what mike <unk> compaq 's president of ___, prediction: the\n",
      "1 ==> it said the N rail cars are in addition to ___, prediction: a\n",
      "2 ==> if the dollar stays weak he says that will add ___, prediction: n\n",
      "3 ==> on a recent saturday night in the midst of west ___, prediction: germany\n",
      "4 ==> it is bigger faster and more profitable than the news ___, prediction: could\n",
      "5 ==> that will translate into sharply higher production profits particularly compared ___, prediction: with\n",
      "6 ==> the sales drop for the no. N car maker may ___, prediction: <unk>\n",
      "7 ==> grumman corp. received an $ N million navy contract to ___, prediction: build\n",
      "8 ==> those that pulled out of stocks <unk> it he said ___, prediction: </s>\n",
      "9 ==> they say investors should sell stocks but not necessarily right ___, prediction: </s>\n",
      "10 ==> the name <unk> in rumors is british petroleum co. which ___, prediction: has\n",
      "11 ==> the <unk> is believed to be the first such cross-border ___, prediction: in\n",
      "12 ==> but recent developments have made the networks and nbc president ___, prediction: bush\n",
      "13 ==> they recently announced increases of a few cents a pound ___, prediction: to\n",
      "14 ==> the inflation-adjusted growth rate for france 's gross domestic product ___, prediction: </s>\n",
      "15 ==> they perhaps had concern that we were getting out of ___, prediction: the\n",
      "16 ==> jeffrey <unk> of program trader <unk> investment group said N ___, prediction: years\n",
      "17 ==> shares of ual the parent of united airlines were extremely ___, prediction: directly\n",
      "18 ==> they do n't want to get caught again says one ___, prediction: of\n",
      "19 ==> the industry <unk> last year and this year as a ___, prediction: result\n",
      "20 ==> the new company is to be called siemens <unk> components ___, prediction: ltd\n",
      "21 ==> the official china daily said retail prices of <unk> foods ___, prediction: and\n",
      "22 ==> trans world airlines inc. offering of $ N million senior ___, prediction: subordinated\n",
      "23 ==> but some big brokerage firms said they do n't expect ___, prediction: to\n",
      "24 ==> people familiar with hilton said over the weekend that the ___, prediction: company\n",
      "25 ==> its parent company hooker corp. of sydney australia is currently ___, prediction: being\n",
      "26 ==> on friday morning before the market 's sell-off the business ___, prediction: <unk>\n",
      "27 ==> in N N N of those aged N to N ___, prediction: the\n",
      "28 ==> the bank 's net income for the nine months ended ___, prediction: sept\n",
      "29 ==> there 's not nearly as much <unk> said john <unk> ___, prediction: a\n"
     ]
    }
   ],
   "source": [
    "### Start your code\n",
    "\n",
    "test_data_sequences = []\n",
    "sampled_texts = random.sample(test_texts, 30)\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    \n",
    "    token_list = tokenizer.texts_to_sequences(text)\n",
    "    test_data_sequences.append(token_list[1:-1][-window_size:])\n",
    "\n",
    "X_test = pad_sequences(test_data_sequences, maxlen=window_size)\n",
    "\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "for i,data in enumerate(zip(sampled_texts, Y_test_pred)):\n",
    "    clean_text = preprocesser.apply(data[0])\n",
    "    tokens = tokenize(clean_text)\n",
    "    pred = list(tokenizer.unique_tokens)[data[1]-1]\n",
    "    print(f'{i} ==> {data[0].strip()}, prediction: {pred}')\n",
    "\n",
    "### End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0c8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS584A_21F_Assignment3_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033f5d5d7d254e0eaa9e8248a922cd24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23bf828777d6427ca881362636957c1f",
       "IPY_MODEL_1d29f3408a014f69a7e5d422012af3df",
       "IPY_MODEL_79f0039ff69d442fb308d2572e45568e"
      ],
      "layout": "IPY_MODEL_777e888395634af98a54350e9afd3173"
     }
    },
    "04b88d3a05db465097d3b6d132b9d4d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08888abc179e4f4db80b340adf3cefc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afd68d6cc3e452b9995c16b45498e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1282ffc696e94bde9d464c086bf56a9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c400992df144367acc8f1684428f24e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d29f3408a014f69a7e5d422012af3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcf4e8ce928244b8b4c07ffe0225fffc",
      "max": 72,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5835dc4965724bb29c0f844c1de605a7",
      "value": 72
     }
    },
    "1e5cbadd09154cae8aa3ed9cffccaecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f3cad8f4790440991d8689a6901092b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef62927dca744b0b0ac405a69077e1d",
      "placeholder": "​",
      "style": "IPY_MODEL_3348deeabd834cc8af78d259c5d264eb",
      "value": "good turing: 100%"
     }
    },
    "22fce55c7fac47be8151cf2aabb19c7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232b015d2d50456199173cf15c705f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa143b50b4a4071966a75797331120c",
       "IPY_MODEL_4fc66537350d420b98eeda74530956e8",
       "IPY_MODEL_b508585491914913af1e97442d173c19"
      ],
      "layout": "IPY_MODEL_ec79cb6402fb48209b04cf141b682e02"
     }
    },
    "23bf828777d6427ca881362636957c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_486338a06f9740ddae037dc655a7d18a",
      "placeholder": "​",
      "style": "IPY_MODEL_d1c4dda64d4d4938ac0592eede0af27a",
      "value": "Evaluating: 100%"
     }
    },
    "28977ef615ed4798abeed10e8f8d3677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3348deeabd834cc8af78d259c5d264eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3545d285dd56410eb867b6bddd64bbfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_798c1eca83ef4409ad5cf05ead9a55c0",
      "placeholder": "​",
      "style": "IPY_MODEL_589fdc916f904eb8a2c14cde025eee02",
      "value": " 3370/3370 [00:22&lt;00:00, 148.03it/s]"
     }
    },
    "366a68482f1b4c9aace014294204a3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f98bb7355c8445c8e6f533c010723df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_554d18a1a4d846b184aa00cbc93a5578",
      "placeholder": "​",
      "style": "IPY_MODEL_1c400992df144367acc8f1684428f24e",
      "value": "perplexity: 100%"
     }
    },
    "43ee7b41140e428ba38e051926a185e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "486338a06f9740ddae037dc655a7d18a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fc66537350d420b98eeda74530956e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22fce55c7fac47be8151cf2aabb19c7e",
      "max": 920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43ee7b41140e428ba38e051926a185e5",
      "value": 27
     }
    },
    "546564a20a2243c1a901562e6e16357e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "554d18a1a4d846b184aa00cbc93a5578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5835dc4965724bb29c0f844c1de605a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "589fdc916f904eb8a2c14cde025eee02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eac3a9da9574e898c0c10b93577b244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61d7f90ab5d140c48dc3dd199b6acf75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "634379b2174944c6a2527d43d6fb21ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661ea4ef6e4c46e4930a9fe6622e15b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6be04f4c233d468595cad6b45aff8040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f013dd9434e4a019af0ffcaf5bc1194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4927eb77cee4fc69c897fb3911f5793",
      "placeholder": "​",
      "style": "IPY_MODEL_ceb86bd353e44e358ade1af7dd367b1a",
      "value": "100%"
     }
    },
    "728ff942c62e4316bee3712f83be0d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73800733b6e549f08c2dc81b292520c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73887cb869e94589b4e5b1b691b6f937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28977ef615ed4798abeed10e8f8d3677",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e5a920068fd48b6b7af469c6e43b2f4",
      "value": 42068
     }
    },
    "75ad4c14843d41a18298b4580ac79663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa61fe57992243f581ae3a2be486164c",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0afd68d6cc3e452b9995c16b45498e0c",
      "value": 42068
     }
    },
    "76435fd43d15403aa6ae09c170d08bff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777e888395634af98a54350e9afd3173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "798c1eca83ef4409ad5cf05ead9a55c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79f0039ff69d442fb308d2572e45568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73800733b6e549f08c2dc81b292520c4",
      "placeholder": "​",
      "style": "IPY_MODEL_e469615a3ad143318cec11ed6ea82346",
      "value": " 72/72 [00:19&lt;00:00,  3.62it/s]"
     }
    },
    "7e51e710fe314164bd358efa9f7c553e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f5cad4515454ac1b3cf13bafe2be8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76435fd43d15403aa6ae09c170d08bff",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_661ea4ef6e4c46e4930a9fe6622e15b6",
      "value": 42068
     }
    },
    "82188772d1a64ddfbf2b18049e8991f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e5a920068fd48b6b7af469c6e43b2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92d196ac95b34d0a9b85fde8c291c863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93d68d9d5ae64d3cb21e70b9e60dad35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96df479f4bce49a6ad50823ca13c7a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a53da36e76a4c078ec997f7ecb19c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f3cad8f4790440991d8689a6901092b",
       "IPY_MODEL_7f5cad4515454ac1b3cf13bafe2be8b7",
       "IPY_MODEL_dcf79d8ac613425fa5680359fcd55e52"
      ],
      "layout": "IPY_MODEL_96df479f4bce49a6ad50823ca13c7a8a"
     }
    },
    "9a8be20f7afd48a38aaaac982a3e020b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3a4277f4ff40078f28d3a0abee11c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fa143b50b4a4071966a75797331120c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b88d3a05db465097d3b6d132b9d4d9",
      "placeholder": "​",
      "style": "IPY_MODEL_366a68482f1b4c9aace014294204a3d4",
      "value": "Traning at epoch 0:   3%"
     }
    },
    "a83a2f6476014b699354aeec51081856": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa61fe57992243f581ae3a2be486164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aebb9ebcf3f642d1ab1cbdc27dc4765c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08888abc179e4f4db80b340adf3cefc4",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e51e710fe314164bd358efa9f7c553e",
      "value": 3370
     }
    },
    "b00b6b54679a43b3bdc1259ad6f0e8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eeb84b4f6bea45a6bcadd12e6a68ee83",
       "IPY_MODEL_aebb9ebcf3f642d1ab1cbdc27dc4765c",
       "IPY_MODEL_da209ecaa8af40e6b771ec773a4596e4"
      ],
      "layout": "IPY_MODEL_d05c534b93d24537924364b5e0f90e41"
     }
    },
    "b2df758ccb7c4ce2ae4ace0d60567536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3518c5087a54b8e90271e5960d91865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728ff942c62e4316bee3712f83be0d4f",
      "placeholder": "​",
      "style": "IPY_MODEL_ffd343e5537b411e821e1c7d1b40fd57",
      "value": " 42068/42068 [04:51&lt;00:00, 146.97it/s]"
     }
    },
    "b508585491914913af1e97442d173c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1282ffc696e94bde9d464c086bf56a9e",
      "placeholder": "​",
      "style": "IPY_MODEL_9e3a4277f4ff40078f28d3a0abee11c1",
      "value": " 27/920 [00:07&lt;04:09,  3.59it/s]"
     }
    },
    "b86c1938fbf54e1f9ec838d22ac8e686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c63c7845afb448adb5e2b791aa6711f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f98bb7355c8445c8e6f533c010723df",
       "IPY_MODEL_f7105aa135ab48fb8ba43a3b6df554a8",
       "IPY_MODEL_3545d285dd56410eb867b6bddd64bbfb"
      ],
      "layout": "IPY_MODEL_b86c1938fbf54e1f9ec838d22ac8e686"
     }
    },
    "c6971f8d9554424c90a42d04cbb42579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d7f90ab5d140c48dc3dd199b6acf75",
      "placeholder": "​",
      "style": "IPY_MODEL_b2df758ccb7c4ce2ae4ace0d60567536",
      "value": "unigram counting: 100%"
     }
    },
    "ceb86bd353e44e358ade1af7dd367b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d05c534b93d24537924364b5e0f90e41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1c4dda64d4d4938ac0592eede0af27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da209ecaa8af40e6b771ec773a4596e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82188772d1a64ddfbf2b18049e8991f0",
      "placeholder": "​",
      "style": "IPY_MODEL_546564a20a2243c1a901562e6e16357e",
      "value": " 3370/3370 [00:23&lt;00:00, 150.49it/s]"
     }
    },
    "db92112fd1404654a3f11dec95a79378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f013dd9434e4a019af0ffcaf5bc1194",
       "IPY_MODEL_73887cb869e94589b4e5b1b691b6f937",
       "IPY_MODEL_e6f545c0008e45ff95ea610c86b10987"
      ],
      "layout": "IPY_MODEL_634379b2174944c6a2527d43d6fb21ca"
     }
    },
    "dcf4e8ce928244b8b4c07ffe0225fffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcf79d8ac613425fa5680359fcd55e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e5cbadd09154cae8aa3ed9cffccaecf",
      "placeholder": "​",
      "style": "IPY_MODEL_5eac3a9da9574e898c0c10b93577b244",
      "value": " 42068/42068 [00:00&lt;00:00, 471213.73it/s]"
     }
    },
    "e469615a3ad143318cec11ed6ea82346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e69bba41e3384f19be77eb2e870ac131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6971f8d9554424c90a42d04cbb42579",
       "IPY_MODEL_75ad4c14843d41a18298b4580ac79663",
       "IPY_MODEL_b3518c5087a54b8e90271e5960d91865"
      ],
      "layout": "IPY_MODEL_92d196ac95b34d0a9b85fde8c291c863"
     }
    },
    "e6f545c0008e45ff95ea610c86b10987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6be04f4c233d468595cad6b45aff8040",
      "placeholder": "​",
      "style": "IPY_MODEL_e94ddfd39d1d4e80937eb1c7257b4526",
      "value": " 42068/42068 [04:49&lt;00:00, 148.55it/s]"
     }
    },
    "e94ddfd39d1d4e80937eb1c7257b4526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec79cb6402fb48209b04cf141b682e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeb84b4f6bea45a6bcadd12e6a68ee83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a8be20f7afd48a38aaaac982a3e020b",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f1f75e05d34717ba63436a403541d4",
      "value": "perplexity: 100%"
     }
    },
    "eef62927dca744b0b0ac405a69077e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4927eb77cee4fc69c897fb3911f5793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7105aa135ab48fb8ba43a3b6df554a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a83a2f6476014b699354aeec51081856",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93d68d9d5ae64d3cb21e70b9e60dad35",
      "value": 3370
     }
    },
    "f7f1f75e05d34717ba63436a403541d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd343e5537b411e821e1c7d1b40fd57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
